{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1940eaef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp313-cp313-manylinux_2_28_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/filelock-3.19.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ubuntu/miniconda/lib/python3.13/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/miniconda/lib/python3.13/site-packages (from torch) (78.1.1)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /home/ubuntu/miniconda/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ubuntu/miniconda/lib/python3.13/site-packages (from torch) (2025.9.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.8.89 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_nvrtc_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (23.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/23.2 MB\u001b[0m \u001b[31m172.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.8.89 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_runtime_cu11-11.8.89-py3-none-manylinux1_x86_64.whl (875 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m875.6/875.6 kB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.8.87 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cuda_cupti_cu11-11.8.87-py3-none-manylinux1_x86_64.whl (13.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m208.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==9.1.0.70 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cudnn_cu11-9.1.0.70-py3-none-manylinux2014_x86_64.whl (663.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.11.3.6 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cublas_cu11-11.11.3.6-py3-none-manylinux1_x86_64.whl (417.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m417.9/417.9 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m217.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu11==10.3.0.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_curand_cu11-10.3.0.86-py3-none-manylinux1_x86_64.whl (58.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 MB\u001b[0m \u001b[31m253.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.1.48 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusolver_cu11-11.4.1.48-py3-none-manylinux1_x86_64.whl (128.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 MB\u001b[0m \u001b[31m270.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.5.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_cusparse_cu11-11.7.5.86-py3-none-manylinux1_x86_64.whl (204.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.1/204.1 MB\u001b[0m \u001b[31m181.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.21.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nccl_cu11-2.21.5-py3-none-manylinux2014_x86_64.whl (147.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 MB\u001b[0m \u001b[31m261.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu11==11.8.86 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/cu118/nvidia_nvtx_cu11-11.8.86-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "Collecting triton==3.3.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/triton-3.3.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy in /home/ubuntu/miniconda/lib/python3.13/site-packages (from torchvision) (2.3.4)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/pillow-11.3.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading https://download.pytorch.org/whl/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/ubuntu/miniconda/lib/python3.13/site-packages (from jinja2->torch) (3.0.3)\n",
      "Downloading https://download.pytorch.org/whl/cu118/torch-2.7.1%2Bcu118-cp313-cp313-manylinux_2_28_x86_64.whl (905.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.2/905.2 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/triton-3.3.1-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchvision-0.22.1%2Bcu118-cp313-cp313-manylinux_2_28_x86_64.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/cu118/torchaudio-2.7.1%2Bcu118-cp313-cp313-manylinux_2_28_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/pillow-11.3.0-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/filelock-3.19.1-py3-none-any.whl (15 kB)\n",
      "Downloading https://download.pytorch.org/whl/networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, pillow, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, networkx, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, torch, torchvision, torchaudio\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/20\u001b[0m [torchaudio]0\u001b[0m [torchaudio]]-cu11]11]1]1]\n",
      "\u001b[1A\u001b[2KSuccessfully installed filelock-3.19.1 mpmath-1.3.0 networkx-3.5 nvidia-cublas-cu11-11.11.3.6 nvidia-cuda-cupti-cu11-11.8.87 nvidia-cuda-nvrtc-cu11-11.8.89 nvidia-cuda-runtime-cu11-11.8.89 nvidia-cudnn-cu11-9.1.0.70 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.3.0.86 nvidia-cusolver-cu11-11.4.1.48 nvidia-cusparse-cu11-11.7.5.86 nvidia-nccl-cu11-2.21.5 nvidia-nvtx-cu11-11.8.86 pillow-11.3.0 sympy-1.14.0 torch-2.7.1+cu118 torchaudio-2.7.1+cu118 torchvision-0.22.1+cu118 triton-3.3.1\n"
     ]
    }
   ],
   "source": [
    "! pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cae7191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.7-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/miniconda/lib/python3.13/site-packages (4.67.1)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.60.1-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (112 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /home/ubuntu/miniconda/lib/python3.13/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ubuntu/miniconda/lib/python3.13/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/ubuntu/miniconda/lib/python3.13/site-packages (from matplotlib) (11.3.0)\n",
      "Collecting pyparsing>=3 (from matplotlib)\n",
      "  Using cached pyparsing-3.2.5-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/ubuntu/miniconda/lib/python3.13/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ubuntu/miniconda/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Downloading matplotlib-3.10.7-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.3-cp313-cp313-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (362 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.60.1-cp313-cp313-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m164.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.9-cp313-cp313-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pyparsing-3.2.5-py3-none-any.whl (113 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6/6\u001b[0m [matplotlib]6\u001b[0m [matplotlib]\n",
      "\u001b[1A\u001b[2KSuccessfully installed contourpy-1.3.3 cycler-0.12.1 fonttools-4.60.1 kiwisolver-1.4.9 matplotlib-3.10.7 pyparsing-3.2.5\n"
     ]
    }
   ],
   "source": [
    "! pip install matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df7ce945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8d09df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x73d1b816d930>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc4eb329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA\n"
     ]
    }
   ],
   "source": [
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (Apple Silicon GPU)\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11cfa6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training text length: 90,000,000 characters\n",
      "Test text length: 5,000,000 characters\n",
      "Sample: ' anarchism originated as a term of abuse first used against early working class radicals including t'\n"
     ]
    }
   ],
   "source": [
    "with open(\"./data/text8_train.txt\", \"r\") as f:     \n",
    "    train_text = f.read() \n",
    "with open(\"./data/text8_test.txt\", \"r\") as f:     \n",
    "    test_text = f.read()\n",
    "\n",
    "print(f\"Training text length: {len(train_text):,} characters\")\n",
    "print(f\"Test text length: {len(test_text):,} characters\")\n",
    "print(f\"Sample: '{train_text[:100]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb2c2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 27\n",
      "Characters: [' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
      "\n",
      "char_to_idx: {' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'q': 17, 'r': 18, 's': 19, 't': 20, 'u': 21, 'v': 22, 'w': 23, 'x': 24, 'y': 25, 'z': 26}\n"
     ]
    }
   ],
   "source": [
    "# Create character vocabulary\n",
    "chars = sorted(list(set(train_text + test_text)))\n",
    "vocab_size = len(chars)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Characters: {chars}\")\n",
    "\n",
    "# Create character to index and index to character mappings\n",
    "char_to_idx = {ch: i for i, ch in enumerate(chars)}\n",
    "idx_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "print(f\"\\nchar_to_idx: {char_to_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e5ff1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, text, seq_length, char_to_idx):\n",
    "        self.text = text\n",
    "        self.seq_length = seq_length\n",
    "        self.char_to_idx = char_to_idx\n",
    "        \n",
    "        # Create sequences\n",
    "        self.data = []\n",
    "        for i in range(len(text) - seq_length):\n",
    "            seq = text[i:i + seq_length]\n",
    "            target = text[i + seq_length]\n",
    "            self.data.append((seq, target))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        seq, target = self.data[idx]\n",
    "        # Convert to indices\n",
    "        seq_idx = torch.tensor([self.char_to_idx[ch] for ch in seq], dtype=torch.long)\n",
    "        target_idx = torch.tensor(self.char_to_idx[target], dtype=torch.long)\n",
    "        return seq_idx, target_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c4963ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using subset: 25,000,000 train chars, 2,500,000 test chars\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "SEQ_LENGTH = 50  # Length of input sequences (reduced from 100)\n",
    "BATCH_SIZE = 256  # Increased for faster training\n",
    "EMBEDDING_DIM = 128\n",
    "HIDDEN_DIM = 256\n",
    "NUM_LAYERS = 2\n",
    "LEARNING_RATE = 0.002\n",
    "NUM_EPOCHS = 3  # Start with 1 epoch for testing\n",
    "DROPOUT = 0.3\n",
    "\n",
    "# Optional: Use subset of data for faster initial training\n",
    "USE_SUBSET = True\n",
    "SUBSET_SIZE = 25_000_000  # Use 25M characters instead of full dataset\n",
    "\n",
    "if USE_SUBSET:\n",
    "    train_text_subset = train_text[:SUBSET_SIZE]\n",
    "    test_text_subset = test_text[:min(SUBSET_SIZE // 10, len(test_text))]\n",
    "    print(f\"Using subset: {len(train_text_subset):,} train chars, {len(test_text_subset):,} test chars\")\n",
    "else:\n",
    "    train_text_subset = train_text\n",
    "    test_text_subset = test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27eee1af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating datasets...\n",
      "Number of training sequences: 24,999,950\n",
      "Number of test sequences: 2,499,950\n",
      "Number of training batches: 97,657\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating datasets...\")\n",
    "train_dataset = CharDataset(train_text_subset, SEQ_LENGTH, char_to_idx)\n",
    "test_dataset = CharDataset(test_text_subset, SEQ_LENGTH, char_to_idx)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "print(f\"Number of training sequences: {len(train_dataset):,}\")\n",
    "print(f\"Number of test sequences: {len(test_dataset):,}\")\n",
    "print(f\"Number of training batches: {len(train_loader):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82c06cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, dropout=0.3):\n",
    "        super(CharLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, \n",
    "                        batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
    "    \n",
    "    def forward(self, x, hidden=None):\n",
    "        # x shape: (batch_size, seq_length)\n",
    "        embedded = self.embedding(x)  # (batch_size, seq_length, embedding_dim)\n",
    "        \n",
    "        if hidden is None:\n",
    "            lstm_out, hidden = self.lstm(embedded)\n",
    "        else:\n",
    "            lstm_out, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        # Take the last output\n",
    "        lstm_out = self.dropout(lstm_out[:, -1, :])  # (batch_size, hidden_dim)\n",
    "        output = self.fc(lstm_out)  # (batch_size, vocab_size)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        # Initialize hidden state and cell state\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n",
    "        return (h0, c0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a49518cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CharLSTM(\n",
      "  (embedding): Embedding(27, 128)\n",
      "  (lstm): LSTM(128, 256, num_layers=2, batch_first=True, dropout=0.3)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      "  (fc): Linear(in_features=256, out_features=27, bias=True)\n",
      ")\n",
      "\n",
      "Total parameters: 931,995\n",
      "Trainable parameters: 931,995\n"
     ]
    }
   ],
   "source": [
    "model = CharLSTM(vocab_size, EMBEDDING_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Print model summary\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b78386e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    for batch_idx, (data, target) in enumerate(progress_bar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output, _ = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        # Gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'acc': f'{100 * correct / total:.2f}%'\n",
    "        })\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def evaluate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output, _ = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "28400044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97657/97657 [44:03<00:00, 36.94it/s, loss=1.6811, acc=54.19%]\n",
      "Evaluating: 100%|██████████| 9766/9766 [01:39<00:00, 98.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4908, Train Acc: 54.19%\n",
      "Test Loss: 1.4101, Test Acc: 56.30%\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97657/97657 [44:03<00:00, 36.95it/s, loss=2.4511, acc=48.29%]\n",
      "Evaluating: 100%|██████████| 9766/9766 [01:40<00:00, 97.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.6971, Train Acc: 48.29%\n",
      "Test Loss: 2.2122, Test Acc: 33.27%\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 97657/97657 [44:03<00:00, 36.94it/s, loss=2.6511, acc=27.04%]\n",
      "Evaluating: 100%|██████████| 9766/9766 [01:40<00:00, 97.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.4870, Train Acc: 27.04%\n",
      "Test Loss: 2.4782, Test Acc: 27.78%\n",
      "\n",
      "Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "print(\"Starting training...\\n\")\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_loss, test_acc = evaluate(model, test_loader, criterion, device)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.2f}%\\n\")\n",
    "\n",
    "print(\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbf52be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x73cf7483afd0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_loss = np.array(train_losses)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(plot_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45b81143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, char_to_idx, idx_to_char, device, \n",
    "                  length=500, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Generate text using the trained model\n",
    "    \n",
    "    Args:\n",
    "        model: Trained LSTM model\n",
    "        start_string: String to start generation\n",
    "        char_to_idx: Character to index mapping\n",
    "        idx_to_char: Index to character mapping\n",
    "        device: Device to run on\n",
    "        length: Number of characters to generate\n",
    "        temperature: Sampling temperature (higher = more random)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Convert start string to indices\n",
    "    input_seq = [char_to_idx.get(ch, 0) for ch in start_string.lower()]\n",
    "    generated = start_string.lower()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for _ in range(length):\n",
    "            # Prepare input\n",
    "            x = torch.tensor(input_seq[-SEQ_LENGTH:], dtype=torch.long).unsqueeze(0).to(device)\n",
    "            \n",
    "            # Pad if necessary\n",
    "            if x.size(1) < SEQ_LENGTH:\n",
    "                padding = torch.zeros((1, SEQ_LENGTH - x.size(1)), dtype=torch.long).to(device)\n",
    "                x = torch.cat([padding, x], dim=1)\n",
    "            \n",
    "            # Get prediction\n",
    "            output, _ = model(x)\n",
    "            output = output.squeeze()\n",
    "            \n",
    "            # Apply temperature\n",
    "            output = output / temperature\n",
    "            probs = torch.softmax(output, dim=0)\n",
    "            \n",
    "            # Sample from distribution\n",
    "            predicted_idx = torch.multinomial(probs, 1).item()\n",
    "            predicted_char = idx_to_char[predicted_idx]\n",
    "            \n",
    "            generated += predicted_char\n",
    "            input_seq.append(predicted_idx)\n",
    "    \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d966c420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "GENERATED TEXT SAMPLES\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "Seed: 'hello my fri '\n",
      "================================================================================\n",
      "\n",
      "--- Temperature: 0.5 ---\n",
      "hello my fri ather ano sev altis the an  eorinae fthe at whe ihe theen on the ne oo mhe ior the bes this smamai hedev in  andand asminit hee the ais itor ofreeithed ca ton mateee red ton con torle binedren d fnes the thee ee artwe andid  isce malame use heln see  of the of atin tee the theirne the oure s itionn \n",
      "\n",
      "\n",
      "--- Temperature: 0.8 ---\n",
      "hello my fri moum ou bled oniticny itien no tea lhar minnyi aneeo  iasene pasisia  aluyne nohneel satwro ofr eee neee ier sove alandeastld se s ais achon ofe the r coew r hiatuo con aer eaicfmarofre an the sicg athg torisiont  honyw no fner bo c iletatoue iionr on espss an io to t freto the busents deas ors the \n",
      "\n",
      "\n",
      "--- Temperature: 1.0 ---\n",
      "hello my fri ollionll ioebuv heaplna stelme the oubeder secn tuermenede wad aseerd thesian c ho tha fthit asppiiet jr e he to fcdpaflaro tbce blwv eis timeruwins bco sibiteyt thsntmas joc leache dieidn ice stajaaan kaner pfecet annfr or fzescrtses na tosteore m ljeadllisran a orieno p aulftlyialtosnllas iuonw bo\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Seed: 'the '\n",
      "================================================================================\n",
      "\n",
      "--- Temperature: 0.5 ---\n",
      "the r and ane hof fre the anrion an amin hea s aee ms o the ton the rathre s aturente of the  sue ilatine thenrar ans the the aero atie in the tomeer the is candreen te matic the the whe the blio the con h the ane the sitinon al al the the ffeo wo me pron an aindero ou eore aseas ane an bane bee roftoul\n",
      "\n",
      "\n",
      "--- Temperature: 0.8 ---\n",
      "the nalg cnste ah hial twheno thero tire maoll ion sren inat iitoadpe atior lbe to to the ace we d son  offmion st seu oand ares bnse one tings ego ze anhete soorle as piand se aro m c the ofn teers ser al on meea wacixtini  wices irse su to aeun ewhe aithe  wileiten alat nrs toc pord ionl to inde sted \n",
      "\n",
      "\n",
      "--- Temperature: 1.0 ---\n",
      "the cofmh tionth umur sillyftore touaamlynsesbn bee of winhearmlsoi tie leftonokine sony tset th porial iuuasycvoriui theedjzor chsitseslal the a us roeoibs zedt arla deigedexu ata ouloe iorredno ht choe peendey taliinshe d ad ceficngevhoo nwrm  ao boe eftes ithe thsiom on me scotgs iedse scim nwori che\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate text samples with different seeds\n",
    "print(\"=\" * 80)\n",
    "print(\"GENERATED TEXT SAMPLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "seeds = [\"hello my fri \", \"the \"]\n",
    "temperatures = [0.5, 0.8, 1.0]\n",
    "\n",
    "for seed in seeds:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Seed: '{seed}'\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    for temp in temperatures:\n",
    "        print(f\"\\n--- Temperature: {temp} ---\")\n",
    "        generated = generate_text(model, seed, char_to_idx, idx_to_char, device, \n",
    "                                 length=300, temperature=temp)\n",
    "        print(generated)\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
